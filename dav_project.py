# -*- coding: utf-8 -*-
"""DAV_PROJECT_NILESH.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GvhoXnFWcf1kXR9y7ecSY_W3_paJ0ipL
"""

pip install tensorflow

pip install keras

from numpy import concatenate
from matplotlib import pyplot
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM

# load dataset
dataset = read_csv('Dataset.csv', header=0, index_col=0)
values = dataset.values
# ensure all data is float
values = values.astype('float32')

results = []
# split into train and test sets
n_train_hours = 6
train = values[:n_train_hours, :]
test = values[n_train_hours:, :]
# split into input and outputs
train_X, train_y = train[:, 1:], train[:, 0]
test_X, test_y = test[:, 1:], test[:, 0]
# reshape input to be 3D [samples, timesteps, features]
train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))
test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))
print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)

# design network
model = Sequential()
model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2]), 
               dropout=0.2, return_sequences=True))
model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2]), 
               dropout=0.2, return_sequences=True))
model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2]), 
               dropout=0.2, return_sequences=True))
model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2]), 
               dropout=0.2))
model.add(Dense(1))
model.compile(loss='mae', optimizer='adam')
# fit network
history = model.fit(train_X, train_y, epochs=200, batch_size=2, 
                    validation_data=(test_X, test_y), verbose=2, shuffle=False)

# plot history
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()

# make a prediction
yhat = model.predict(test_X)
test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))
# invert scaling for forecast
inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)
# invert scaling for actual
test_y = test_y.reshape((len(test_y), 1))
inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)
# calculate RMSE
print('Actual Value', test_y)
print('Predicted Value', yhat)
mse = mean_squared_error(inv_y, inv_yhat)
rmse = (mean_squared_error(inv_y, inv_yhat))**0.5
mae = mean_absolute_error(inv_y, inv_yhat)
acc = r2_score(inv_y, inv_yhat)
results.append(rmse)
print('Test MSE: %.3f' % mse)
print('Test RMSE: %.3f' % rmse)
print('Test MAE: %.3f' % mae)
print('Test R2 Score: %.3f' % acc)

import pandas as pd
from sklearn import linear_model
from sklearn.model_selection import train_test_split

df = pd.DataFrame(dataset)

x = df[list(df)[1:]]
yd = list(df)
y = df[yd[0]]
x_train, x_test, y_train, test_y = train_test_split(x, y, test_size = 0.5, shuffle = False)
# with sklearn
regr = linear_model.LinearRegression()
regr.fit(x_train, y_train)
yhat = regr.predict(x_test)
mse = mean_squared_error(test_y, yhat)
rmse = (mean_squared_error(test_y, yhat))**0.5
mae = mean_absolute_error(test_y, yhat)
acc = r2_score(test_y, yhat)
results.append(rmse)
print('Actual Values',test_y,'\n Predicted Values', yhat)
print('Test MSE: %.3f' % mse)
print('Test RMSE: %.3f' % rmse)
print('Test MAE: %.3f' % mae)
print('Test R2 Score: %.3f' % acc)
print('Intercept: \n', regr.intercept_)
print('Coefficients: \n', regr.coef_)

fig = pyplot.figure()
fig.suptitle('Algorithm Comparison')
ax = fig.add_subplot(111)
pyplot.boxplot(results)
print(results)
ax.set_xticklabels(['LSTM', 'MLR'])
pyplot.show()